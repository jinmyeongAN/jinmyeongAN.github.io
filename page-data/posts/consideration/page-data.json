{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/consideration","result":{"pageContext":{"currentCategory":"consideration","categories":["All","consideration","business","블로그","featured"],"edges":[{"node":{"id":"635f55ef-32c1-5417-9eea-9ab7cd12d5ee","excerpt":"AI should be able to learn from just a few examples, like what humans usually do - Denny Zhou - 🤔 의외로 잘 모르는 CoT NLP 연구를 하면서 Chain-of-Thought (CoT) [1] 를 듣지 않기란 쉽지 않다. 그러나, 생각해보니 얕은 깊이의 개념 정도만 인지하고 있을뿐 CoT에 대해 깊이 생각해본적이 없고, 심지어 CoT 논문도 제대로 읽어본적도 없다…!! 이번 기회에 CoT 뿐만 아니라, 이후 후속연구도 보면서 CoT가 가지고 있는 insight을 파헤쳐 보려한다. 이번 글은 특히 “LLM Reasoning: Key Ideas and Limitations” [2] 글에 큰 영향을 받았다. 📌 Prompt 기반 Intermediate steps (rationale) CoT 논문을 보다보면 Intermediate steps이라는 용어가 자주 등장한다. Intermediate steps이란 정답을…","fields":{"slug":"/consideration-CoT/"},"frontmatter":{"categories":"consideration","title":"CoT에 대한 고찰","date":"November 13, 2024"}},"next":{"fields":{"slug":"/today-company-Antropic/"}},"previous":null}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}